{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818e75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python libraries\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Data handling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# PyTorch and related libraries\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Transformers library for NLP tasks\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Visualization and utility libraries\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "\n",
    "# Deep learning libraries\n",
    "import torchvision\n",
    "import torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31dc0bee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIELD_NOTES_ID</th>\n",
       "      <th>WELL_TEST_ID</th>\n",
       "      <th>COMMENT_CATEGORY</th>\n",
       "      <th>ODOUR_CAT</th>\n",
       "      <th>FIELD_NOTE_COMMENTS</th>\n",
       "      <th>CREATE_TIMESTAMP</th>\n",
       "      <th>CREATE_USERID</th>\n",
       "      <th>H2S_TESTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1058147</td>\n",
       "      <td>3569</td>\n",
       "      <td>Landowner</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Landowner indicated good water quality.</td>\n",
       "      <td>38:47.7</td>\n",
       "      <td>CONVERSION</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1058149</td>\n",
       "      <td>9782</td>\n",
       "      <td>Landowner</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Landowner indicated good water quality.</td>\n",
       "      <td>38:47.7</td>\n",
       "      <td>CONVERSION</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1058151</td>\n",
       "      <td>3570</td>\n",
       "      <td>Landowner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Water has sulfur taste and odour and is someti...</td>\n",
       "      <td>38:47.7</td>\n",
       "      <td>CONVERSION</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1058153</td>\n",
       "      <td>4649</td>\n",
       "      <td>Landowner</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Landowner indicates poor water quality. Methan...</td>\n",
       "      <td>38:47.7</td>\n",
       "      <td>CONVERSION</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1058155</td>\n",
       "      <td>840</td>\n",
       "      <td>Landowner</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Landowner indicated good quality water with si...</td>\n",
       "      <td>38:47.7</td>\n",
       "      <td>CONVERSION</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIELD_NOTES_ID  WELL_TEST_ID COMMENT_CATEGORY  ODOUR_CAT  \\\n",
       "0         1058147          3569        Landowner        1.0   \n",
       "1         1058149          9782        Landowner        1.0   \n",
       "2         1058151          3570        Landowner        3.0   \n",
       "3         1058153          4649        Landowner        1.0   \n",
       "4         1058155           840        Landowner        1.0   \n",
       "\n",
       "                                 FIELD_NOTE_COMMENTS CREATE_TIMESTAMP  \\\n",
       "0            Landowner indicated good water quality.          38:47.7   \n",
       "1            Landowner indicated good water quality.          38:47.7   \n",
       "2  Water has sulfur taste and odour and is someti...          38:47.7   \n",
       "3  Landowner indicates poor water quality. Methan...          38:47.7   \n",
       "4  Landowner indicated good quality water with si...          38:47.7   \n",
       "\n",
       "  CREATE_USERID  H2S_TESTED  \n",
       "0    CONVERSION         NaN  \n",
       "1    CONVERSION         0.0  \n",
       "2    CONVERSION         NaN  \n",
       "3    CONVERSION         1.0  \n",
       "4    CONVERSION         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "db_path = 'bwwt.db'  # Replace with the actual path to your SQLite database file\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Define the SQL query to retrieve data from the table\n",
    "query = 'SELECT * FROM FIELD_NOTES'\n",
    "\n",
    "# Use pandas to read the query result into a DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36c3b7",
   "metadata": {},
   "source": [
    "# Cleanse 'FIELD_NOTE_COMMENTS' of form entries\n",
    "\n",
    "Form entries in the format shown below and since they are in a difference language format with ü serving as a checkmark, should not be included.\n",
    "\n",
    "\n",
    "\n",
    "'Is the water supply currently enough for your present requirements?   Yes  ü     No _____ \n",
    "\n",
    "'Is the water supply currently enough for your present requirements?   Yes  ü     No _____ \n",
    "\n",
    "\n",
    "TASTE:         Good   ü   Fair ___ Poor ___ Comments: __________________________________________\n",
    "\n",
    "ODOUR:       Good   ü  Fair ___ Poor ___ Comments: __________________________________________\n",
    "\n",
    "COLOUR:     Good   ü   Fair ___ Poor ___ Comments: ___________________________________________\n",
    "\n",
    "SEDIMENT:  Good  ü    Fair ___ Poor ___ Comments: __________________________________________\n",
    "\n",
    "GAS OBSERVED IN WATER:   Yes  __  No  ü'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2305a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame where 'FIELD_NOTE_COMMENTS' contains 'ü'\n",
    "contains_u_form_df = df[df['FIELD_NOTE_COMMENTS'].str.contains('ü', case=False, na=False)]\n",
    "\n",
    "# Create a DataFrame where 'FIELD_NOTE_COMMENTS' does not contain 'ü'\n",
    "no_u_form_df = df[~df['FIELD_NOTE_COMMENTS'].str.contains('ü', case=False, na=False)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3ae319",
   "metadata": {},
   "source": [
    "# Drop nulls from Field Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c2eb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_field_notes_cleaned = no_u_form_df.dropna(subset=['FIELD_NOTE_COMMENTS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d1936",
   "metadata": {},
   "source": [
    "# Import Manually Labelled Field Notes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1648eec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1698, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab rows where field notes have been manually labelled \n",
    "df_labelled = no_u_form_df[pd.notna(no_u_form_df['ODOUR_CAT'])]\n",
    "\n",
    "# Drop rows with 'ODOUR_CAT' values 0 and 1 (values where odour is not mentioned: 1, or there is a checklist: 0)\n",
    "\n",
    "# 3 means there was an odour, and 2 means there was no odour, or the odour was decribed as good\n",
    "\n",
    "df_labelled = df_labelled[~df_labelled['ODOUR_CAT'].isin([0, 1])]\n",
    "\n",
    "# Replace values in 'ODOUR_CAT' column\n",
    "df_labelled['ODOUR_CAT'] = df_labelled['ODOUR_CAT'].replace({3: 1, 2: 0})\n",
    "\n",
    "df_labelled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ce5163",
   "metadata": {},
   "source": [
    "# Find comments that mention odour by searching for comments that contain a list of words related to smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f39a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "smell_words = ['odour', 'odor', 'smell', 'smells', 'sulphur', 'rotten egg', 'scent']\n",
    "\n",
    "smell_words_df = df_field_notes_cleaned[df_field_notes_cleaned['FIELD_NOTE_COMMENTS'].str.contains('|'.join(smell_words), case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5518b0",
   "metadata": {},
   "source": [
    "# Create a balanced df of labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9734a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def random_undersample(df, target_column, minority_class_value, majority_class_value, undersample_ratio=1.0, random_seed=None):\n",
    "    \"\"\"\n",
    "    Randomly undersample a binary categorical feature in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - target_column (str): The column to undersample.\n",
    "    - minority_class_value: The value representing the minority class.\n",
    "    - majority_class_value: The value representing the majority class.\n",
    "    - undersample_ratio (float): The ratio of the number of minority class samples to keep.\n",
    "    - random_seed (int or None): Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The undersampled DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate majority and minority classes\n",
    "    majority_class = df[df[target_column] == majority_class_value]\n",
    "    minority_class = df[df[target_column] == minority_class_value]\n",
    "\n",
    "    # Undersample majority class\n",
    "    undersampled_majority = resample(\n",
    "        majority_class,\n",
    "        replace=False,\n",
    "        n_samples=int(len(minority_class) * undersample_ratio),\n",
    "        random_state=random_seed\n",
    "    )\n",
    "\n",
    "    # Concatenate minority class and undersampled majority class\n",
    "    undersampled_df = pd.concat([minority_class, undersampled_majority])\n",
    "\n",
    "    return undersampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2c6404c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "undersampled_labelled=random_undersample(df_labelled, 'ODOUR_CAT', 1, 0, undersample_ratio=1.0, random_seed=9898)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd975478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25dbb3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = undersampled_labelled.FIELD_NOTE_COMMENTS.values\n",
    "labels = undersampled_labelled['ODOUR_CAT'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84afeb2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Download the tokenizer for 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=False)\n",
    "\n",
    "# Save the tokenizer to a local directory (optional)\n",
    "#tokenizer.save_pretrained('bert-base-uncased-tokenizer')\n",
    "\n",
    "# You can now use the 'tokenizer' object to tokenize and encode text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd31d7c3",
   "metadata": {},
   "source": [
    "# Print Random Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9192675a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════╤═════════════╕\n",
      "│ Tokens    │   Token IDs │\n",
      "╞═══════════╪═════════════╡\n",
      "│ [UNK]     │         100 │\n",
      "├───────────┼─────────────┤\n",
      "│ indicated │        5393 │\n",
      "├───────────┼─────────────┤\n",
      "│ hard      │        2524 │\n",
      "├───────────┼─────────────┤\n",
      "│ water     │        2300 │\n",
      "├───────────┼─────────────┤\n",
      "│ with      │        2007 │\n",
      "├───────────┼─────────────┤\n",
      "│ iron      │        3707 │\n",
      "├───────────┼─────────────┤\n",
      "│ o         │        1051 │\n",
      "├───────────┼─────────────┤\n",
      "│ ##dou     │       26797 │\n",
      "├───────────┼─────────────┤\n",
      "│ ##r       │        2099 │\n",
      "├───────────┼─────────────┤\n",
      "│ .         │        1012 │\n",
      "├───────────┼─────────────┤\n",
      "│ [UNK]     │         100 │\n",
      "├───────────┼─────────────┤\n",
      "│ stain     │       21101 │\n",
      "├───────────┼─────────────┤\n",
      "│ ##ing     │        2075 │\n",
      "├───────────┼─────────────┤\n",
      "│ caused    │        3303 │\n",
      "├───────────┼─────────────┤\n",
      "│ by        │        2011 │\n",
      "├───────────┼─────────────┤\n",
      "│ water     │        2300 │\n",
      "├───────────┼─────────────┤\n",
      "│ .         │        1012 │\n",
      "├───────────┼─────────────┤\n",
      "│ [UNK]     │         100 │\n",
      "├───────────┼─────────────┤\n",
      "│ field     │        2492 │\n",
      "├───────────┼─────────────┤\n",
      "│ 600       │        5174 │\n",
      "├───────────┼─────────────┤\n",
      "│ m         │        1049 │\n",
      "├───────────┼─────────────┤\n",
      "│ south     │        2148 │\n",
      "├───────────┼─────────────┤\n",
      "│ of        │        1997 │\n",
      "├───────────┼─────────────┤\n",
      "│ well      │        2092 │\n",
      "├───────────┼─────────────┤\n",
      "│ .         │        1012 │\n",
      "╘═══════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from tabulate import tabulate\n",
    "def print_rand_sentence():\n",
    "  '''Displays the tokens and respective IDs of a random text sample'''\n",
    "  index = random.randint(0, len(text)-1)\n",
    "  table = np.array([tokenizer.tokenize(text[index]), \n",
    "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n",
    "  print(tabulate(table,\n",
    "                 headers = ['Tokens', 'Token IDs'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e7f97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\dychi\\anaconda3\\envs\\cuttings\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "  '''\n",
    "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
    "    - input_ids: list of token ids\n",
    "    - token_type_ids: list of token type ids\n",
    "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
    "  '''\n",
    "  return tokenizer.encode_plus(\n",
    "                        input_text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )\n",
    "\n",
    "\n",
    "for sample in text:\n",
    "    encoding_dict = preprocessing(sample, tokenizer)\n",
    "    token_id.append(encoding_dict['input_ids']) \n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "\n",
    "token_id = torch.cat(token_id, dim = 0)\n",
    "attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "\n",
    "labels = torch.tensor(labels)\n",
    "labels = labels.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c14870d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════╤═════════════╤══════════════════╕\n",
      "│ Tokens    │   Token IDs │   Attention Mask │\n",
      "╞═══════════╪═════════════╪══════════════════╡\n",
      "│ [CLS]     │         101 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [UNK]     │         100 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ water     │        2300 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ is        │        2003 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ not       │        2025 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ pumped    │       16486 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ for       │        2005 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ a         │        1037 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ long      │        2146 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ time      │        2051 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ it        │        2009 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ comes     │        3310 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ out       │        2041 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ black     │        2304 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ ,         │        1010 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ but       │        2021 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ clears    │       28837 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ up        │        2039 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ after     │        2044 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ being     │        2108 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ run       │        2448 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ .         │        1012 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [UNK]     │         100 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ notice    │        5060 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ a         │        1037 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ rotten    │       11083 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ egg       │        8288 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ o         │        1051 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ ##dou     │       26797 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ ##r       │        2099 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ sometimes │        2823 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ .         │        1012 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [SEP]     │         102 │                1 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "├───────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]     │           0 │                0 │\n",
      "╘═══════════╧═════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "def print_rand_sentence_encoding():\n",
    "    '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
    "    \n",
    "    index = random.randint(0, len(text) - 1)\n",
    "    tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
    "    token_ids = [i.numpy() for i in token_id[index]]\n",
    "    attention = [i.numpy() for i in attention_masks[index]]\n",
    "\n",
    "    table = np.array([tokens, token_ids, attention]).T\n",
    "    print(tabulate(table, \n",
    "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence_encoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aefd47",
   "metadata": {},
   "source": [
    "# Train and Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c452f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "\n",
    "val_ratio = 0.2\n",
    "# Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "batch_size = 16\n",
    "\n",
    "# Indices of the train and validation splits stratified by labels\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True,\n",
    "    stratify = labels)\n",
    "\n",
    "# Train and validation sets\n",
    "train_set = TensorDataset(token_id[train_idx], \n",
    "                          attention_masks[train_idx], \n",
    "                          labels[train_idx])\n",
    "\n",
    "val_set = TensorDataset(token_id[val_idx], \n",
    "                        attention_masks[val_idx], \n",
    "                        labels[val_idx])\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,\n",
    "            sampler = RandomSampler(train_set),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_set,\n",
    "            sampler = SequentialSampler(val_set),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "242e1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_tp(preds, labels):\n",
    "    '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
    "    return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fp(preds, labels):\n",
    "    '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
    "    return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_tn(preds, labels):\n",
    "    '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
    "    return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fn(preds, labels):\n",
    "    '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
    "    return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "\n",
    "def b_metrics(preds, labels):\n",
    "    '''Returns the following metrics:\n",
    "    - accuracy    = (TP + TN) / N\n",
    "    - precision   = TP / (TP + FP)\n",
    "    - recall      = TP / (TP + FN)\n",
    "    - specificity = TN / (TN + FP)'''\n",
    "    preds = np.argmax(preds, axis = 1).flatten()\n",
    "    labels = labels.flatten()\n",
    "    tp = b_tp(preds, labels)\n",
    "    tn = b_tn(preds, labels)\n",
    "    fp = b_fp(preds, labels)\n",
    "    fn = b_fn(preds, labels)\n",
    "    b_accuracy = (tp + tn) / len(labels)\n",
    "    b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
    "    b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
    "    b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
    "    return b_accuracy, b_precision, b_recall, b_specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9d36c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. GPU will be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU will be used.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. CPU will be used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6394d9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the BertForSequenceClassification model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels = 2,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr = 5e-5,\n",
    "                              eps = 1e-08\n",
    "                              )\n",
    "\n",
    "# Run on GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51a8b189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|██████████████████████████████████████▌                                      | 1/2 [00:22<00:22, 22.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.5502\n",
      "\t - Validation Accuracy: 0.8646\n",
      "\t - Validation Precision: 0.9209\n",
      "\t - Validation Recall: 0.8062\n",
      "\t - Validation Specificity: 0.9171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|█████████████████████████████████████████████████████████████████████████████| 2/2 [00:43<00:00, 21.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.3420\n",
      "\t - Validation Accuracy: 0.8542\n",
      "\t - Validation Precision: 0.9727\n",
      "\t - Validation Recall: 0.7356\n",
      "\t - Validation Specificity: 0.9674\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "epochs = 2\n",
    "\n",
    "for _ in trange(epochs, desc = 'Epoch'):\n",
    "    \n",
    "    # ========== Training ==========\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        train_output = model(b_input_ids, \n",
    "                             token_type_ids = None, \n",
    "                             attention_mask = b_input_mask, \n",
    "                             labels = b_labels)\n",
    "        # Backward pass\n",
    "        train_output.loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += train_output.loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    # ========== Validation ==========\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    val_accuracy = []\n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    val_specificity = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "          # Forward pass\n",
    "          eval_output = model(b_input_ids, \n",
    "                              token_type_ids = None, \n",
    "                              attention_mask = b_input_mask)\n",
    "        logits = eval_output.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate validation metrics\n",
    "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
    "        val_accuracy.append(b_accuracy)\n",
    "        # Update precision only when (tp + fp) !=0; ignore nan\n",
    "        if b_precision != 'nan': val_precision.append(b_precision)\n",
    "        # Update recall only when (tp + fn) !=0; ignore nan\n",
    "        if b_recall != 'nan': val_recall.append(b_recall)\n",
    "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
    "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
    "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
    "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
    "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f91dc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: there was a funny odour in the sample\n",
      "Predicted Class: test_for_H2S\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "# New sentence\n",
    "new_sentence = \"there was a funny odour in the sample\"\n",
    "\n",
    "\n",
    "\n",
    "# We need Token IDs and Attention Mask for inference on the new sentence\n",
    "test_ids = []\n",
    "test_attention_mask = []\n",
    "\n",
    "# Apply the tokenizer\n",
    "encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "# Extract IDs and Attention Mask\n",
    "test_ids.append(encoding['input_ids'])\n",
    "test_attention_mask.append(encoding['attention_mask'])\n",
    "test_ids = torch.cat(test_ids, dim=0)\n",
    "test_attention_mask = torch.cat(test_attention_mask, dim=0)\n",
    "\n",
    "# Forward pass, calculate logit predictions\n",
    "with torch.no_grad():\n",
    "    output = model(test_ids.to(device), token_type_ids=None, attention_mask=test_attention_mask.to(device))\n",
    "\n",
    "# Assuming you have a LabelEncoder for converting model predictions to class labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the classes\n",
    "class_labels = [\"do_not_test\", \"test_for_H2S\"]\n",
    "\n",
    "# Create a LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Set the classes for the LabelEncoder\n",
    "label_encoder.classes_ = class_labels\n",
    "\n",
    "\n",
    "prediction = label_encoder.classes_[np.argmax(output.logits.cpu().numpy())]\n",
    "\n",
    "print('Input Sentence:', new_sentence)\n",
    "print('Predicted Class:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12bafd9",
   "metadata": {},
   "source": [
    "# Make predictions using a pre-trained natural language processing (NLP) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc920589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dychi\\AppData\\Local\\Temp\\ipykernel_30564\\1271194124.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  smell_words_df['MODEL_PREDICTION'] = smell_words_df['FIELD_NOTE_COMMENTS'].apply(predict_smell)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIELD_NOTES_ID</th>\n",
       "      <th>WELL_TEST_ID</th>\n",
       "      <th>COMMENT_CATEGORY</th>\n",
       "      <th>ODOUR_CAT</th>\n",
       "      <th>FIELD_NOTE_COMMENTS</th>\n",
       "      <th>CREATE_TIMESTAMP</th>\n",
       "      <th>CREATE_USERID</th>\n",
       "      <th>H2S_TESTED</th>\n",
       "      <th>MODEL_PREDICTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1058151</td>\n",
       "      <td>3570</td>\n",
       "      <td>Landowner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Water has sulfur taste and odour and is someti...</td>\n",
       "      <td>38:47.7</td>\n",
       "      <td>CONVERSION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1058161</td>\n",
       "      <td>6812</td>\n",
       "      <td>Landowner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Well used for domestic purposes, well complete...</td>\n",
       "      <td>38:47.7</td>\n",
       "      <td>CONVERSION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1058163</td>\n",
       "      <td>3059</td>\n",
       "      <td>Landowner</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Rust rings in house. Landowner indicated fair ...</td>\n",
       "      <td>38:47.7</td>\n",
       "      <td>CONVERSION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1058167</td>\n",
       "      <td>6536</td>\n",
       "      <td>Landowner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Landowner indicated good water quality but exp...</td>\n",
       "      <td>38:47.7</td>\n",
       "      <td>CONVERSION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1058169</td>\n",
       "      <td>3378</td>\n",
       "      <td>Landowner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Landowner indicated good taste until 2-3 weeks...</td>\n",
       "      <td>38:47.7</td>\n",
       "      <td>CONVERSION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FIELD_NOTES_ID  WELL_TEST_ID COMMENT_CATEGORY  ODOUR_CAT  \\\n",
       "2          1058151          3570        Landowner        3.0   \n",
       "7          1058161          6812        Landowner        3.0   \n",
       "8          1058163          3059        Landowner        2.0   \n",
       "10         1058167          6536        Landowner        3.0   \n",
       "11         1058169          3378        Landowner        3.0   \n",
       "\n",
       "                                  FIELD_NOTE_COMMENTS CREATE_TIMESTAMP  \\\n",
       "2   Water has sulfur taste and odour and is someti...          38:47.7   \n",
       "7   Well used for domestic purposes, well complete...          38:47.7   \n",
       "8   Rust rings in house. Landowner indicated fair ...          38:47.7   \n",
       "10  Landowner indicated good water quality but exp...          38:47.7   \n",
       "11  Landowner indicated good taste until 2-3 weeks...          38:47.7   \n",
       "\n",
       "   CREATE_USERID  H2S_TESTED  MODEL_PREDICTION  \n",
       "2     CONVERSION         NaN                 1  \n",
       "7     CONVERSION         NaN                 1  \n",
       "8     CONVERSION         NaN                 0  \n",
       "10    CONVERSION         NaN                 1  \n",
       "11    CONVERSION         NaN                 1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_smell(text):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "    # New sentence\n",
    "    new_sentence = text\n",
    "\n",
    "    # We need Token IDs and Attention Mask for inference on the new sentence\n",
    "    test_ids = []\n",
    "    test_attention_mask = []\n",
    "\n",
    "    # Apply the tokenizer\n",
    "    encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "    # Extract IDs and Attention Mask\n",
    "    test_ids.append(encoding['input_ids'])\n",
    "    test_attention_mask.append(encoding['attention_mask'])\n",
    "    test_ids = torch.cat(test_ids, dim=0)\n",
    "    test_attention_mask = torch.cat(test_attention_mask, dim=0)\n",
    "\n",
    "    # Forward pass, calculate logit predictions\n",
    "    with torch.no_grad():\n",
    "        output = model(test_ids.to(device), token_type_ids=None, attention_mask=test_attention_mask.to(device))\n",
    "\n",
    "    # Assuming you have a LabelEncoder for converting model predictions to class labels\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # Define the classes\n",
    "    class_labels = [0, 1]\n",
    "\n",
    "    # Create a LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Set the classes for the LabelEncoder\n",
    "    label_encoder.classes_ = class_labels\n",
    "\n",
    "\n",
    "    prediction = label_encoder.classes_[np.argmax(output.logits.cpu().numpy())]\n",
    "\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# Create a new column 'MODEL_PREDICTION' with the model predictions\n",
    "smell_words_df['MODEL_PREDICTION'] = smell_words_df['FIELD_NOTE_COMMENTS'].apply(predict_smell)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "smell_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e332841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rust rings in house. Landowner indicated fair water taste and odour, some sediment and good color.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FIELD_NOTES_ID                                                   1058163\n",
       "WELL_TEST_ID                                                        3059\n",
       "COMMENT_CATEGORY                                               Landowner\n",
       "ODOUR_CAT                                                            2.0\n",
       "FIELD_NOTE_COMMENTS    Rust rings in house. Landowner indicated fair ...\n",
       "CREATE_TIMESTAMP                                                 38:47.7\n",
       "CREATE_USERID                                                 CONVERSION\n",
       "H2S_TESTED                                                           NaN\n",
       "MODEL_PREDICTION                                                       0\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(smell_words_df['FIELD_NOTE_COMMENTS'].iloc[2])\n",
    "smell_words_df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88bc4bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well used for domestic/stock purposes, well completed with a pitless adapter, 152mm well diameter, submersible pump /pressure tank system cannot be bypassed, no water treatment system, well chlorinated by owner in November 2005, slight sulphur smell, no gas present, water quality and pumping test completed when drilled, well has been in consistent use and pumped daily, no fuel stored on site, septic field located 75m East-Southeast of well.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FIELD_NOTES_ID                                                   1058261\n",
       "WELL_TEST_ID                                                        7554\n",
       "COMMENT_CATEGORY                                               Landowner\n",
       "ODOUR_CAT                                                            NaN\n",
       "FIELD_NOTE_COMMENTS    Well used for domestic/stock purposes, well co...\n",
       "CREATE_TIMESTAMP                                                 38:47.7\n",
       "CREATE_USERID                                                 CONVERSION\n",
       "H2S_TESTED                                                           NaN\n",
       "MODEL_PREDICTION                                                       1\n",
       "Name: 57, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = pd.isna(smell_words_df['ODOUR_CAT'])\n",
    "\n",
    "# Use the mask to filter the DataFrame\n",
    "unlabelled_rows = smell_words_df[mask]\n",
    "\n",
    "print(unlabelled_rows['FIELD_NOTE_COMMENTS'].iloc[2])\n",
    "unlabelled_rows.iloc[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuttings]",
   "language": "python",
   "name": "conda-env-cuttings-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
